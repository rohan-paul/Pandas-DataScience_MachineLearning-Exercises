{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Categorical variables are those values which are selected from a group of categories or\n",
    "labels. For example, the variable may be “color” and may take on the values “red,” “green,” and “green.” Or the variable Gender with the values of male or female is categorical, and so is the variable marital status with the values of never married, married, divorced, or widowed.\n",
    "\n",
    "Another example, in survey about preferred brand of car they owned, the result would be categorical (e.g. Tesla, Toyota, Ford, None, etc.). Responses fall into a fixed set of categories.\n",
    "\n",
    "I will get error if you try to plug these variables into most machine learning models without \"encoding\" them first.\n",
    "\n",
    "Almost all Machine learning and deep learning neural networks algorithms require that input and output variables are numbers, requiring that categorical data must be encoded to numbers before we can use it to feed to models and evaluate a model.\n",
    "\n",
    "There are quite a few techniques to encode categorical variables for modeling, although the three most common are as follows:\n",
    "\n",
    "- Integer Encoding: Where each unique label is mapped to an integer.\n",
    "\n",
    "- One Hot Encoding: Where each label is mapped to a binary vector.\n",
    "\n",
    "- Learned Embedding: Where a distributed representation of the categories is learned.\n",
    "\n",
    "In some categorical variables, the labels have an intrinsic order, for example, in the variable Student's grade, the values of A, B, C, or Fail are ordered, A being the highest grade and Fail the lowest. These are called ordinal categorical variables. Variables in which the categories do not have an intrinsic order are called nominal categorical variables, such as the variable City, with the values of London, Manchester, Bristol, and so on.\n",
    "\n",
    "The values of categorical variables are often encoded as strings. Scikit-learn, does not support strings as values, therefore, we need to transform those strings into numbers. The act of replacing strings with numbers is called categorical encoding.\n",
    "\n",
    "## One-hot Encoding\n",
    "\n",
    "In one-hot encoding, we represent a categorical variable as a group of binary variables,\n",
    "where each binary variable represents one category. The binary variable indicates whether\n",
    "the category is present in an observation (1) or not (0).\n",
    "\n",
    "One hot encoding is the most widespread approach, and it works very well unless our categorical variable takes on a large number of values (e.g. more than 20 different values)\n",
    "\n",
    "![img](https://i.imgur.com/5td19b8.jpg)\n",
    "\n",
    "Another example with a variable named 'color'. The values in the variable are Red, Yellow and Green. And then we create a separate column for each possible value. Wherever the original value was Red, we put a 1 in the Red column.\n",
    "\n",
    "![img](https://i.imgur.com/kdltIHI.png)\n",
    "\n",
    "From the above Gender variable, we can derive the binary variable of Female, which shows the value of 1 for females, or the binary variable of Male, which takes the value of 1 for the males in the dataset.\n",
    "For the categorical variable of Color with the values of red, green, and green, we can create three variables called red, green, and green. These variables will take the value of 1 if the\n",
    "observation is red, green, or green, respectively, or 0 otherwise.\n",
    "\n",
    "A categorical variable with k unique categories can be encoded in k-1 binary variables. For Gender, k is 2 as it contains two labels (male and female), therefore, we need to create only one binary variable (k - 1 = 1) to capture all of the information. For the color variable, which has three categories (k=3; red, green, and green), we need to create two (k - 1 = 2) binary variables to capture all the information, so that the following occurs:\n",
    "\n",
    "- If the observation is red, it will be captured by the variable red (red = 1, green = 0).\n",
    "\n",
    "- f the observation is green, it will be captured by the variable green (red = 0, green = 1).\n",
    "\n",
    "- If the observation is green, it will be captured by the combination of red and green (red = 0, green = 0).\n",
    "\n",
    "There are a few occasions in which we may prefer to encode the categorical variables with k binary variables:\n",
    "\n",
    "- When training decision trees, as they do not evaluate the entire feature space at the same time\n",
    "- When selecting features recursively\n",
    "- When determining the importance of each category within a variable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "breast_cancer_df = pd.read_csv('../input/breast-cancer-data/breast-cancer.data')\n",
    "print('Breast Cancer df number of rows and columns are ', breast_cancer_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Replace the question marks in the dataset with NumPy NaN values:\n",
    "breast_cancer_df = breast_cancer_df.replace('?', np.nan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a list with the variable names:\n",
    "# There are 10 columns as we know the from the shape of the dataframe\n",
    "# So create list of 10 column-headings starting with 'A1' and ending with 'A-10'\n",
    "# Meaning I have to traverser a range of 1 to 11\n",
    "column_labels = ['A' + str(s) for s in range(1, 11)]\n",
    "column_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now assign the above list of as column-label\n",
    "breast_cancer_df.columns = column_labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make lists with categorical and numerical variables:\n",
    "\n",
    "category_columns = [c for c in breast_cancer_df.columns if breast_cancer_df[c].dtypes == 'O' ]\n",
    "numeric_columns = [c for c in breast_cancer_df.columns if breast_cancer_df[c].dtypes != 'O' ]\n",
    "\n",
    "print('breast_cancer_category_columns ', category_columns)\n",
    "print('breast_cancer_numeric_columns ', numeric_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the above we see that column 'A7' is the Numeric Column and the, rest all are categorical column.\n",
    "Now, re-cast numerical variables to float types:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "breast_cancer_df['A7'] = breast_cancer_df['A7'].astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Re-code the target variable as binary:\n",
    "Which is the column label of 'A10'. That is making each 'yes' as 1 and each 'no' as 0 (zero)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "breast_cancer_df['A10'] = breast_cancer_df['A10'].map({'yes':1, 'no':0})\n",
    "breast_cancer_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fill in the missing data\n",
    "breast_cancer_df[numeric_columns] =  breast_cancer_df[numeric_columns].fillna(0)\n",
    "breast_cancer_df[category_columns] = breast_cancer_df[category_columns].fillna(0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# separate the data into train and test sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_df.drop(labels=['A10'], axis=1), breast_cancer_df['A10'], test_size=0.3, random_state=0)\n",
    "\n",
    "#  Let's inspect the unique categories of the A8 variable:\n",
    "X_train['A8'].unique()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  Let's inspect the unique categories of the A3 variable\n",
    "X_train['A3'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So I have the unique values as\n",
    "\n",
    "array(['ge40', 'premeno', 'lt40'], dtype=object)\n",
    "\n",
    "---\n",
    "\n",
    "## one-hot encoding using pandas get_dummies()\n",
    "\n",
    "Let's encode A3 into k-1 binary variables using pandas and then inspect the first five rows of the resulting dataframe:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp_1 = pd.get_dummies(X_train['A3'], drop_first=True)\n",
    "tmp_1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tmp_2 = pd.get_dummies(X_train['A3'], drop_first=False)\n",
    "tmp_2.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`get_dummies` pandas function converts categorical variables into indicator variables and  ignores missing data, unless we specifically indicate otherwise, in which case, it will return missing data as an additional category\n",
    "\n",
    " To encode the variable into k binaries, use instead `drop_first=False`.\n",
    "\n",
    "From the output above we can see each label is now a binary variable and there's two (because we used k - 1 ) new columns for the label-names.\n",
    "\n",
    "To understand how the get_dummies() implementation take a look at the below code"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'country': ['russia', 'germany', 'australia','korea']})\n",
    "df_get_dummied = pd.get_dummies(df['country'], prefix='country')\n",
    "df_get_dummied"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![img](https://i.imgur.com/DgTHD0B.jpg)\n",
    "\n",
    "To encode all categorical variables at the same time, let's first make a list with their names: i.e.\n",
    " - I am excluding A7 (which is numerical data) and\n",
    " - A10 (which is the target variable and I have make it to be binary previously.\n",
    " - Also excluding all the age ranges i.e 'A2', 'A4', 'A5', 'A8'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vars_categorical = ['A1', 'A3', 'A6', 'A8', 'A9' ]\n",
    "\n",
    "# Now, let's encode all of the categorical variables into k-1 binaries each, capturing the result in a new dataframe:\n",
    "\n",
    "X_train_dummy_encoded_pandas = pd.get_dummies(X_train[vars_categorical], drop_first=True)\n",
    "X_test_dummy_encoded = pd.get_dummies(X_test[vars_categorical], drop_first=True )\n",
    "\n",
    "X_train_dummy_encoded_pandas.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So as we can see above, the pandas' `get_dummies()` function will create one binary variable per found category. Hence, if there are more categories in the train set than in the test set, get_dummies() will return more columns in the transformed train set than in the transformed test set.\n",
    "\n",
    "---\n",
    "\n",
    "## Now one-hot encoding using scikit-learn\n",
    "\n",
    "First create a OneHotEncoder transformer that encodes into k-1 binary variables and returns a NumPy array:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder_scikit_learn = OneHotEncoder(categories='auto', drop='first', sparse=False)\n",
    "\n",
    "# Now fit i.e. make scikit_learn to learn the encoder to a slice of the train set with the categorical variables so it identifies the categories to encode:\n",
    "encoder_scikit_learn.fit(X_train[vars_categorical])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scikit-learn's `OneHotEncoder()` function will only encode the categories learned from the train set. If there are new categories in the test set, we can instruct the encoder to ignore them or to return an error with the `handle_unknown='ignore'` argument or the `handle_unknown='error'` argument, respectively. \n",
    "\n",
    "Now, let's create the NumPy arrays with the binary variables for train and test sets:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_encoded_scikit = encoder_scikit_learn.transform(X_train[vars_categorical])\n",
    "\n",
    "X_train_encoded_scikit.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_encoded_scikit = encoder_scikit_learn.transform(X_test[vars_categorical])\n",
    "\n",
    "X_test_encoded_scikit.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unfortunately, the feature names are not preserved in the NumPy array, therefore, identifying which feature was derived from which variable is not straightforward."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}