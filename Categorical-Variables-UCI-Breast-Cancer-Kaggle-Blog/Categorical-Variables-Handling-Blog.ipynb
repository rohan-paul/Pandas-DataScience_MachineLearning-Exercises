{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from feature_engine.categorical_encoders import OneHotCategoricalEncoder\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## What is Categorical Data\n",
    "\n",
    "Categorical variables are those values which are selected from a group of categories or\n",
    "labels. Typically, any data attribute which is categorical in nature represents discrete values which belong to a specific finite set of categories or classes. These are also often known as classes or labels in the context of attributes or variables which are to be predicted by a model (popularly known as response variables). These discrete values can be text or numeric in nature (or even unstructured data like images!).\n",
    "\n",
    "#### There are two major classes of categorical data, nominal and ordinal.\n",
    "\n",
    "In any nominal categorical data attribute, there is no concept of ordering amongst the values of that attribute. Consider a simple example of weather categories like - sunny, cloudy, rainy etc. These are without any concept or notion of order (windy doesn’t always occur before sunny nor is it smaller or bigger than sunny).\n",
    "\n",
    " For example, the variable may be “color” and may take on the values “red,” “green,” and “green.” Or the variable Gender with the values of male or female is categorical, and so is the variable marital status with the values of never married, married, divorced, or widowed.\n",
    "\n",
    "Another example, in survey about preferred brand of car they owned, the result would be categorical (e.g. Tesla, Toyota, Ford, None, etc.). Responses fall into a fixed set of categories.\n",
    "\n",
    "**Ordinal categorical** attributes have some sense or notion of order amongst its values. For instance say shirt sizes. It is quite evident that order or in this case ‘size’ matters when thinking about shirts (S is smaller than M which is smaller than L and so on).\n",
    "\n",
    "---\n",
    "\n",
    "I will get error if you try to plug these variables into most machine learning models without \"encoding\" them first.\n",
    "\n",
    "Almost all Machine learning and deep learning neural networks algorithms require that input and output variables are numbers, requiring that categorical data must be encoded to numbers before we can use it to feed to models and evaluate a model.\n",
    "\n",
    "There are quite a few techniques to encode categorical variables for modeling, although the three most common are as follows:\n",
    "\n",
    "- Integer Encoding: Where each unique label is mapped to an integer.\n",
    "\n",
    "- One Hot Encoding: Where each label is mapped to a binary vector.\n",
    "\n",
    "- Learned Embedding: Where a distributed representation of the categories is learned.\n",
    "\n",
    "In some categorical variables, the labels have an intrinsic order, for example, in the variable Student's grade, the values of A, B, C, or Fail are ordered, A being the highest grade and Fail the lowest. These are called ordinal categorical variables. Variables in which the categories do not have an intrinsic order are called nominal categorical variables, such as the variable City, with the values of London, Manchester, Bristol, and so on.\n",
    "\n",
    "The values of categorical variables are often encoded as strings. Scikit-learn, does not support strings as values, therefore, we need to transform those strings into numbers. The act of replacing strings with numbers is called categorical encoding.\n",
    "\n",
    "## One-hot Encoding\n",
    "\n",
    "One-hot encoding is where you represent each possible value for a category as a separate feature.\n",
    "\n",
    "In one-hot encoding, we represent a categorical variable as a group of binary variables, where each binary variable represents one category. The binary variable indicates whether the category is present in an observation (1) or not (0).\n",
    "\n",
    "One hot encoding is the most widespread approach, and it works very well unless our categorical variable takes on a large number of values (e.g. more than 20 different values)\n",
    "\n",
    "![img](https://i.imgur.com/5td19b8.jpg)\n",
    "\n",
    "Another example with a variable named 'color'. The values in the variable are Red, Yellow and Green. And then we create a separate column for each possible value. Wherever the original value was Red, we put a 1 in the Red column.\n",
    "\n",
    "![img](https://i.imgur.com/kdltIHI.png)\n",
    "\n",
    "From the above Gender variable, we can derive the binary variable of Female, which shows the value of 1 for females, or the binary variable of Male, which takes the value of 1 for the males in the dataset.\n",
    "For the categorical variable of Color with the values of red, green, and green, we can create three variables called red, green, and green. These variables will take the value of 1 if the\n",
    "observation is red, green, or green, respectively, or 0 otherwise.\n",
    "\n",
    "A categorical variable with k unique categories can be encoded in k-1 binary variables. For Gender, k is 2 as it contains two labels (male and female), therefore, we need to create only one binary variable (k - 1 = 1) to capture all of the information. For the color variable, which has three categories (k=3; red, green, and green), we need to create two (k - 1 = 2) binary variables to capture all the information, so that the following occurs:\n",
    "\n",
    "- If the observation is red, it will be captured by the variable red (red = 1, green = 0).\n",
    "\n",
    "- f the observation is green, it will be captured by the variable green (red = 0, green = 1).\n",
    "\n",
    "- If the observation is green, it will be captured by the combination of red and green (red = 0, green = 0).\n",
    "\n",
    "There are a few occasions in which we may prefer to encode the categorical variables with k binary variables:\n",
    "\n",
    "- When training decision trees, as they do not evaluate the entire feature space at the same time\n",
    "- When selecting features recursively\n",
    "- When determining the importance of each category within a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer df number of rows and columns are  (285, 10)\n"
     ]
    }
   ],
   "source": [
    "breast_cancer_df = pd.read_csv('../input/breast-cancer-data/breast-cancer.data')\n",
    "print('Breast Cancer df number of rows and columns are ', breast_cancer_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the question marks in the dataset with NumPy NaN values:\n",
    "breast_cancer_df = breast_cancer_df.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list with the variable names:\n",
    "# There are 10 columns as we know the from the shape of the dataframe\n",
    "# So create list of 10 column-headings starting with 'A1' and ending with 'A-10'\n",
    "# Meaning I have to traverser a range of 1 to 11\n",
    "column_labels = ['A' + str(s) for s in range(1, 11)]\n",
    "column_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now assign the above list of as column-label\n",
    "breast_cancer_df.columns = column_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breast_cancer_category_columns  ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A8', 'A9', 'A10']\n",
      "breast_cancer_numeric_columns  ['A7']\n"
     ]
    }
   ],
   "source": [
    "# Make lists with categorical and numerical variables:\n",
    "\n",
    "category_columns = [c for c in breast_cancer_df.columns if breast_cancer_df[c].dtypes == 'O' ]\n",
    "numeric_columns = [c for c in breast_cancer_df.columns if breast_cancer_df[c].dtypes != 'O' ]\n",
    "\n",
    "print('breast_cancer_category_columns ', category_columns)\n",
    "print('breast_cancer_numeric_columns ', numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the above we see that column 'A7' is the Numeric Column and the, rest all are categorical column.\n",
    "Now, re-cast numerical variables to float types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "breast_cancer_df['A7'] = breast_cancer_df['A7'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Binary encoding - Re-code the target variable as binary:\n",
    "Binary encodings are a special case of category features. Here's a way to do this, do it to the column label of 'A10'. That is making each 'yes' as 1 and each 'no' as 0 (zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right_up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>20-24</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>60-69</td>\n",
       "      <td>ge40</td>\n",
       "      <td>15-19</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>right</td>\n",
       "      <td>left_up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>40-49</td>\n",
       "      <td>premeno</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>right</td>\n",
       "      <td>right_low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no-recurrence-events</td>\n",
       "      <td>60-69</td>\n",
       "      <td>ge40</td>\n",
       "      <td>15-19</td>\n",
       "      <td>0-2</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>left</td>\n",
       "      <td>left_low</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A1     A2       A3     A4   A5  A6   A7     A8  \\\n",
       "0  no-recurrence-events  40-49  premeno  20-24  0-2  no  2.0  right   \n",
       "1  no-recurrence-events  40-49  premeno  20-24  0-2  no  2.0   left   \n",
       "2  no-recurrence-events  60-69     ge40  15-19  0-2  no  2.0  right   \n",
       "3  no-recurrence-events  40-49  premeno    0-4  0-2  no  2.0  right   \n",
       "4  no-recurrence-events  60-69     ge40  15-19  0-2  no  2.0   left   \n",
       "\n",
       "          A9  A10  \n",
       "0   right_up    0  \n",
       "1   left_low    0  \n",
       "2    left_up    0  \n",
       "3  right_low    0  \n",
       "4   left_low    0  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer_df['A10'] = breast_cancer_df['A10'].map({'yes':1, 'no':0})\n",
    "breast_cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in the missing data\n",
    "breast_cancer_df[numeric_columns] =  breast_cancer_df[numeric_columns].fillna(0)\n",
    "breast_cancer_df[category_columns] = breast_cancer_df[category_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# separate the data into train and test sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_df.drop(labels=['A10'], axis=1), breast_cancer_df['A10'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ge40', 'premeno', 'lt40'], dtype=object)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Let's inspect the unique categories of the A3 variable\n",
    "X_train['A3'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So I have the unique values as\n",
    "\n",
    "array(['ge40', 'premeno', 'lt40'], dtype=object)\n",
    "\n",
    "---\n",
    "\n",
    "## one-hot encoding using pandas get_dummies()\n",
    "\n",
    "Let's encode A3 into k-1 binary variables using pandas and then inspect the first five rows of the resulting dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lt40</th>\n",
       "      <th>premeno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lt40  premeno\n",
       "18      0        0\n",
       "156     0        1\n",
       "235     0        1\n",
       "233     0        0\n",
       "234     0        1"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_1 = pd.get_dummies(X_train['A3'], drop_first=True)\n",
    "tmp_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ge40</th>\n",
       "      <th>lt40</th>\n",
       "      <th>premeno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ge40  lt40  premeno\n",
       "18      1     0        0\n",
       "156     0     0        1\n",
       "235     0     0        1\n",
       "233     1     0        0\n",
       "234     0     0        1"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_2 = pd.get_dummies(X_train['A3'], drop_first=False)\n",
    "tmp_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`get_dummies` pandas function converts categorical variables into indicator variables and  ignores missing data, unless we specifically indicate otherwise, in which case, it will return missing data as an additional category\n",
    "\n",
    " To encode the variable into k binaries, use instead `drop_first=False`.\n",
    "\n",
    "From the output above we can see each label is now a binary variable and there's two (because we used k - 1 ) new columns for the label-names.\n",
    "\n",
    "To understand how the get_dummies() implementation take a look at the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_australia</th>\n",
       "      <th>country_germany</th>\n",
       "      <th>country_korea</th>\n",
       "      <th>country_russia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_australia  country_germany  country_korea  country_russia\n",
       "0                  0                0              0               1\n",
       "1                  0                1              0               0\n",
       "2                  1                0              0               0\n",
       "3                  0                0              1               0"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'country': ['russia', 'germany', 'australia','korea']})\n",
    "df_get_dummied = pd.get_dummies(df['country'], prefix='country')\n",
    "df_get_dummied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![img](https://i.imgur.com/DgTHD0B.jpg)\n",
    "\n",
    "To encode all categorical variables at the same time, let's first make a list with their names: i.e.\n",
    " - I am excluding A7 (which is numerical data) and\n",
    " - A10 (which is the target variable and I have make it to be binary previously.\n",
    " - Also excluding all the age ranges i.e 'A2', 'A4', 'A5', 'A8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_recurrence-events</th>\n",
       "      <th>A3_lt40</th>\n",
       "      <th>A3_premeno</th>\n",
       "      <th>A6_no</th>\n",
       "      <th>A6_yes</th>\n",
       "      <th>A8_right</th>\n",
       "      <th>A9_left_low</th>\n",
       "      <th>A9_left_up</th>\n",
       "      <th>A9_right_low</th>\n",
       "      <th>A9_right_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1_recurrence-events  A3_lt40  A3_premeno  A6_no  A6_yes  A8_right  \\\n",
       "18                      0        0           0      1       0         1   \n",
       "156                     0        0           1      1       0         0   \n",
       "235                     1        0           1      1       0         1   \n",
       "233                     1        0           0      1       0         1   \n",
       "234                     1        0           1      0       1         0   \n",
       "\n",
       "     A9_left_low  A9_left_up  A9_right_low  A9_right_up  \n",
       "18             0           0             0            1  \n",
       "156            0           0             0            0  \n",
       "235            1           0             0            0  \n",
       "233            0           1             0            0  \n",
       "234            1           0             0            0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_categorical = ['A1', 'A3', 'A6', 'A8', 'A9' ]\n",
    "\n",
    "# Now, let's encode all of the categorical variables into k-1 binaries each, capturing the result in a new dataframe:\n",
    "\n",
    "X_train_dummy_encoded_pandas = pd.get_dummies(X_train[vars_categorical], drop_first=True)\n",
    "X_test_dummy_encoded = pd.get_dummies(X_test[vars_categorical], drop_first=True )\n",
    "\n",
    "X_train_dummy_encoded_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So as we can see above, the pandas' `get_dummies()` function will create one binary variable per found category. Hence, if there are more categories in the train set than in the test set, get_dummies() will return more columns in the transformed train set than in the transformed test set.\n",
    "\n",
    "---\n",
    "\n",
    "## Now one-hot encoding using scikit-learn\n",
    "\n",
    "First, Create a label (category) encoder object with LabelEncoder() which is a utility class to help normalize labels such that they contain only values between 0 and n_classes-1.\n",
    "\n",
    "#### Why we need Label Encoding\n",
    "\n",
    "Datasets in Machine Learning, usually contains multiple labels in one or more than one columns. These labels can be in the form of words, to make the data understandable i.e. to keep it in human readable form.\n",
    "\n",
    "Label Encoding refers to converting these labels into numeric form so as to convert it into the machine-readable form. Machine learning algorithms can then decide in a better way on how those labels must be operated. It is an important pre-processing step for the structured dataset in supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country\n",
       "0      India\n",
       "1  Australia\n",
       "2        USA"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.DataFrame(['India', 'Australia', 'USA'], columns= ['Country'])\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### How do we do Numeric encoding from the above DataFrame for the Country feature?\n",
    "\n",
    "Ans is with Scikit learn transformation, called LabelEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Country_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Country_encoded\n",
       "0      India                1\n",
       "1  Australia                0\n",
       "2        USA                2"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df['Country_encoded'] = LabelEncoder().fit_transform(example_df['Country'])\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's take a closer look at what the LabelEncoder is doing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(example_df['Country'])\n",
    "encoder.classes_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given the output - array(['Australia', 'India', 'USA'], dtype=object)\n",
    "\n",
    "We see that the ordering of the list of classes above corresponds to their numeric values. Transformation is then as follows:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Now apply LabelEncoder() to our Breast-Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label (category) encoder List:  ['A1', 'A3', 'A6', 'A8', 'A9']\n",
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "\n",
    "enc.fit(vars_categorical)\n",
    "\n",
    "# View the labels (if you want)\n",
    "print(\"label (category) encoder List: \", list(enc.classes_))\n",
    "# ['A1', 'A3', 'A6', 'A8', 'A9']\n",
    "\n",
    "new_cat_features = enc.transform(vars_categorical)\n",
    "print(new_cat_features) # [0 1 2 3 4]\n",
    "\n",
    "new_cat_features = new_cat_features.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a OneHotEncoder transformer that encodes into k-1 binary variables and returns a NumPy array:\n",
    "\n",
    "Scikit-learn's `OneHotEncoder()` function will only encode the categories learned from the train set. If there are new categories in the test set, we can instruct the encoder to ignore them or to return an error with the `handle_unknown='ignore'` argument or the `handle_unknown='error'` argument, respectively.\n",
    "\n",
    "setting the `categories='auto'` argument so that the transformer learns the categories to encode from the train set; `drop='first'` so that the transformer drops the first binary variable, returning k-1 binary features per categorical variable; and sparse=False so that the transformer returns a NumPy array (the default is to return a sparse matrix).\n",
    "\n",
    "Now, let's create the NumPy arrays with the binary variables for train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ohe_scikit = OneHotEncoder(sparse=False, categories='auto', drop='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Now fit i.e. make scikit_learn to learn the encoder to a slice of the train set with the categorical variables so it identifies the categories to encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "output = ohe_scikit.fit_transform(new_cat_features)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Unfortunately, the feature names are not preserved in the NumPy array, therefore, identifying which feature was derived from which variable is not straightforward.\n",
    "\n",
    "The beauty of pandas' `get_dummies()` function is that it returns feature names that clearly indicate which variable and which category each feature represents. On the downside, `get_dummies()` does not persist the information learned from the train set to the test set.\n",
    "\n",
    "Contrarily, scikit-learn's `OneHotEncoder()` function can persist the information from the train set, but it returns a NumPy array, where the information about the meaning of the features is lost.\n",
    "\n",
    "Scikit-learn's `OneHotEncoder()` function will create binary indicators from all variables in the dataset, so be mindful not to pass numerical variables when fitting or transforming your datasets.\n",
    "\n",
    "##  Implement one-hot encoding with Feature-engine\n",
    "\n",
    "`Feature-engine` has multiple advantages:\n",
    "\n",
    "- first, it allows us to select the variables to encode directly in the transformer.\n",
    "- Second, it returns a pandas dataframe with clear variable names, and\n",
    "- third, it preserves the information learned from the train set, therefore returning the same number of columns in\n",
    "both train and test sets.\n",
    "\n",
    "#### With that, Feature-engine overcomes the limitations of pandas' `get_dummies()` method and scikit-learn's `OneHotEncoder()` class.\n",
    "\n",
    "From its [documentation](https://feature-engine.readthedocs.io/en/latest/encoders/OneHotCategoricalEncoder.html)\n",
    "\n",
    "The OneHotCategoricalEncoder() replaces categorical variables by a set of binary variables, one per unique category. The encoder has the option to create k or k-1 binary variables, where k is the number of unique categories.\n",
    "\n",
    "The encoder can also create binary variables for the n most popular categories, n being determined by the user. This means, if we encode the 6 more popular categories, we will only create binary variables for those categories, and the rest will be dropped.\n",
    "\n",
    "The OneHotCategoricalEncoder() works only with categorical variables. A list of variables can be indicated, or the encoder will automatically select all categorical variables in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "one_hot_enc_feature_engine = OneHotCategoricalEncoder(top_categories=None, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With top_categories=None, we indicate that we want to encode all of the categories present in the categorical variables.\n",
    "Feature-engine detects the categorical variables automatically. To encode only a subset of the categorical variables, we can pass the variable names in a list like below:\n",
    "\n",
    "`one_hot_enc_feature_engine = OneHotCategoricalEncoder(variables=['A1', 'A4'])`\n",
    "\n",
    "Now, let's fit the encoder to the train set so that it learns the categories and variables to encode:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "one_hot_enc_feature_engine.fit(X_train)\n",
    "\n",
    "# Let's encode the categorical variables in train and test sets, and display the first five rows of the encoded train set:\n",
    "\n",
    "X_train_enc_feature_engine = one_hot_enc_feature_engine.transform(X_train)\n",
    "X_test_enc_feature_engine = one_hot_enc_feature_engine.transform(X_test)\n",
    "\n",
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## one-hot encoding of frequent categories\n",
    "\n",
    "#### What is high cardinality of a dataset.\n",
    "\n",
    "A dataset which has columns(feature) with high number of unique values. Another way to refer to variables that have a multitude of categories, is to call them variables with high cardinality. If we have categorical variables containing many multiple labels or high cardinality,then by using one hot encoding, we will expand the feature space dramatically, which is not an ideal situation to be in.\n",
    "\n",
    "One approach used by many in Kaggle competitions, is to replace each label of the categorical variable by the count, this is the amount of times each label appears in the dataset. Or the frequency, this is the percentage of observations within that category.\n",
    "\n",
    "But the the cost of the above strategy is some loss of information, because I am effectively turning a categorical feature into a \"popularity\" feature.\n",
    "\n",
    "Check the \"Count Encoding\" section on [this link](https://www.kaggle.com/matleonard/categorical-encodings)\n",
    "\n",
    "While dealing with highly cardinal dataset, one thing to ensure that the cardinality of the categorical information in the training set resembles that in the test/validation sets. That is, if I have a feature with values {A,A,A,B,C,C,D} in train, but test only has {A,B,B}, then eliminating the C and D records, and undersampling the A or oversampling the B records may resist overfitting. Also, for individual featuers with low cardinality, it's often worth bucketing them. In the above example, you may end up replacement values for A and C, and then bucketing B and D into an \"Other\" category\n",
    "\n",
    "We will deal with High-Cardinality with **OneHotCategoricalEncoder** from `feature_engine`\n",
    "\n",
    "One-hot encoding represents each category of a categorical variable with a binary variable. Hence, one-hot encoding of highly cardinal variables or datasets with multiple categorical features can expand the feature space dramatically. To reduce the number of binary variables, we can perform one-hot encoding of the most frequent categories only. One-hot encoding of top categories is equivalent to treating the remaining, less frequent categories as a single, unique category\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}